{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# OpenAI API"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "943fa4e7ab947b96"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())  # read local .env file\n",
    "\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T10:16:44.099487Z",
     "start_time": "2024-01-15T10:16:43.538986Z"
    }
   },
   "id": "e313fc70ebc02fd8",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "schema = {\n",
    "    \"title\": \"Template\",\n",
    "    \"description\": \"The properties of the result.\",\n",
    "    \"required\": [\"result\"],\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "       \"result\": {\n",
    "           \"type\": \"array\",\n",
    "           \"description\": \"The result of the prompt\",\n",
    "           \"items\": {\n",
    "               \"type\": \"object\",\n",
    "               \"required\": [\"nlptask\", \"numberOfPrompts\"],\n",
    "               \"properties\": {\n",
    "                   \"nlptask\": {\n",
    "                       \"type\": \"string\",\n",
    "                       \"description\": \"The name of the NLP task\",\n",
    "                   },\n",
    "                   \"numberOfPrompts\": {\n",
    "                       \"type\": \"integer\",\n",
    "                       \"description\": \"The number of prompts that were classified as the NLP task\",\n",
    "                   },\n",
    "               }\n",
    "           }\n",
    "       }\n",
    "    }\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T10:16:50.328344Z",
     "start_time": "2024-01-15T10:16:50.287733Z"
    }
   },
   "id": "f798c770d6868120",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"Classify the given prompts according to NLP tasks.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    functions = [\n",
    "        {\"name\": \"classify_prompts\", \"parameters\": schema}\n",
    "    ]\n",
    "    function_call = {\n",
    "        \"name\": \"classify_prompts\",\n",
    "    }\n",
    "    response = openai.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        functions=functions,\n",
    "        function_call=function_call,\n",
    "        temperature=0,  # this is the degree of randomness of the model's output\\n\",\n",
    "    )\n",
    "    return response.choices[0].message.function_call.arguments"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T10:16:51.490250Z",
     "start_time": "2024-01-15T10:16:51.465699Z"
    }
   },
   "id": "960aec4294724191",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "# P3"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e263e0144f91ebb6"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-22T09:45:59.419549Z",
     "start_time": "2024-01-22T09:45:58.140948Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from promptsource.templates import TemplateCollection, get_templates_data_frame"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                        id                 dataset  subset  \\\n0     94577b75-2eac-4eae-b367-3b413c4188c6              super_glue  record   \n1     24c267d4-359e-40a9-83d2-bff904d63b09              super_glue  record   \n2     e68d13c5-df75-4de0-b59e-f2eaf4af6ce7              super_glue  record   \n3     df8d0822-2cad-42de-8191-687ae47f6098              super_glue  record   \n4     64013fb3-1afd-4e5a-8777-b164ca3b8e18              super_glue  record   \n...                                    ...                     ...     ...   \n2080  eed32ee4-ebc3-499f-ba61-e91461f56ccb  acronym_identification    None   \n2081  64f438f2-9968-459f-82d2-24bad632b358  acronym_identification    None   \n2082  e4e42433-0e37-4aa5-bbce-7f336ecac6a3  acronym_identification    None   \n2083  cae58242-cde9-472d-ae9e-56fc7e79c0d1  acronym_identification    None   \n2084  8832e5f7-7c45-46da-b85f-71fcb444f264  acronym_identification    None   \n\n                                                 name  \\\n0           Add sentence after (continuation choices)   \n1     Add sentence after after (continuation choices)   \n2                                 Can you figure outâ€¦   \n3                  GPT-3 style (continuation choices)   \n4     GPT-3 style summary only (continuation choices)   \n...                                               ...   \n2080                                     find_acronym   \n2081                             find_acronym_meaning   \n2082                     find_acronyms_and_expansions   \n2083                               list_abbreviations   \n2084                                  list_expansions   \n\n                                              reference  original_task  \\\n0                                                                 True   \n1                                                                 True   \n2                                                                 True   \n3                                     Brown et al. 2020           True   \n4                                     Brown et al. 2020           True   \n...                                                 ...            ...   \n2080  Given the tokens, find the abbreviation for an...           True   \n2081  Given the tokens, find the expansion of an abb...           True   \n2082  Given the tokens, find the abbreviation mappin...           True   \n2083  Given the tokens, list the abbreviations. Metr...           True   \n2084  Given the tokens, list the expansion tokens. M...           True   \n\n     choices_in_prompt     metrics  \\\n0                False  [Accuracy]   \n1                False  [Accuracy]   \n2                False     [Squad]   \n3                False  [Accuracy]   \n4                False  [Accuracy]   \n...                ...         ...   \n2080             False     [Other]   \n2081             False     [Other]   \n2082             False     [Other]   \n2083             False     [Other]   \n2084             False     [Other]   \n\n                                         answer_choices  \\\n0     {% for entity in entities[:-1] %} {{ query | r...   \n1     {% for entity in entities[:-1] %} {{ query | r...   \n2                          {{ entities | join(\"|||\") }}   \n3     {% for entity in entities[:-1] %} - {{ query |...   \n4     {% for entity in entities[:-1] %} - {{ query |...   \n...                                                 ...   \n2080                                               None   \n2081                                               None   \n2082                                               None   \n2083                                               None   \n2084                                               None   \n\n                                                  jinja  \n0     After reading the article, write another sente...  \n1     Summary:\\n\\n- {{ passage.split(\"@highlight\")[1...  \n2     {{ passage }} \\n{{ query }} \\nCan you figure o...  \n3     {{ passage | replace(\"@highlight\", \"\\n- \") }} ...  \n4     {{ passage.split(\"@highlight\")[0] }}\\n\\nSummar...  \n...                                                 ...  \n2080  {% set random_exp = '' %}{% set _dummy = none ...  \n2081  {% set random_abbr = '' %}\\n{% set _dummy = no...  \n2082  {% set _dummy = none %}\\n{% set abbr_exp_dict ...  \n2083  List all the acryonyms in the following space-...  \n2084  List all the expansions (meanings) of the acro...  \n\n[2085 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>dataset</th>\n      <th>subset</th>\n      <th>name</th>\n      <th>reference</th>\n      <th>original_task</th>\n      <th>choices_in_prompt</th>\n      <th>metrics</th>\n      <th>answer_choices</th>\n      <th>jinja</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>94577b75-2eac-4eae-b367-3b413c4188c6</td>\n      <td>super_glue</td>\n      <td>record</td>\n      <td>Add sentence after (continuation choices)</td>\n      <td></td>\n      <td>True</td>\n      <td>False</td>\n      <td>[Accuracy]</td>\n      <td>{% for entity in entities[:-1] %} {{ query | r...</td>\n      <td>After reading the article, write another sente...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>24c267d4-359e-40a9-83d2-bff904d63b09</td>\n      <td>super_glue</td>\n      <td>record</td>\n      <td>Add sentence after after (continuation choices)</td>\n      <td></td>\n      <td>True</td>\n      <td>False</td>\n      <td>[Accuracy]</td>\n      <td>{% for entity in entities[:-1] %} {{ query | r...</td>\n      <td>Summary:\\n\\n- {{ passage.split(\"@highlight\")[1...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>e68d13c5-df75-4de0-b59e-f2eaf4af6ce7</td>\n      <td>super_glue</td>\n      <td>record</td>\n      <td>Can you figure outâ€¦</td>\n      <td></td>\n      <td>True</td>\n      <td>False</td>\n      <td>[Squad]</td>\n      <td>{{ entities | join(\"|||\") }}</td>\n      <td>{{ passage }} \\n{{ query }} \\nCan you figure o...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>df8d0822-2cad-42de-8191-687ae47f6098</td>\n      <td>super_glue</td>\n      <td>record</td>\n      <td>GPT-3 style (continuation choices)</td>\n      <td>Brown et al. 2020</td>\n      <td>True</td>\n      <td>False</td>\n      <td>[Accuracy]</td>\n      <td>{% for entity in entities[:-1] %} - {{ query |...</td>\n      <td>{{ passage | replace(\"@highlight\", \"\\n- \") }} ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>64013fb3-1afd-4e5a-8777-b164ca3b8e18</td>\n      <td>super_glue</td>\n      <td>record</td>\n      <td>GPT-3 style summary only (continuation choices)</td>\n      <td>Brown et al. 2020</td>\n      <td>True</td>\n      <td>False</td>\n      <td>[Accuracy]</td>\n      <td>{% for entity in entities[:-1] %} - {{ query |...</td>\n      <td>{{ passage.split(\"@highlight\")[0] }}\\n\\nSummar...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2080</th>\n      <td>eed32ee4-ebc3-499f-ba61-e91461f56ccb</td>\n      <td>acronym_identification</td>\n      <td>None</td>\n      <td>find_acronym</td>\n      <td>Given the tokens, find the abbreviation for an...</td>\n      <td>True</td>\n      <td>False</td>\n      <td>[Other]</td>\n      <td>None</td>\n      <td>{% set random_exp = '' %}{% set _dummy = none ...</td>\n    </tr>\n    <tr>\n      <th>2081</th>\n      <td>64f438f2-9968-459f-82d2-24bad632b358</td>\n      <td>acronym_identification</td>\n      <td>None</td>\n      <td>find_acronym_meaning</td>\n      <td>Given the tokens, find the expansion of an abb...</td>\n      <td>True</td>\n      <td>False</td>\n      <td>[Other]</td>\n      <td>None</td>\n      <td>{% set random_abbr = '' %}\\n{% set _dummy = no...</td>\n    </tr>\n    <tr>\n      <th>2082</th>\n      <td>e4e42433-0e37-4aa5-bbce-7f336ecac6a3</td>\n      <td>acronym_identification</td>\n      <td>None</td>\n      <td>find_acronyms_and_expansions</td>\n      <td>Given the tokens, find the abbreviation mappin...</td>\n      <td>True</td>\n      <td>False</td>\n      <td>[Other]</td>\n      <td>None</td>\n      <td>{% set _dummy = none %}\\n{% set abbr_exp_dict ...</td>\n    </tr>\n    <tr>\n      <th>2083</th>\n      <td>cae58242-cde9-472d-ae9e-56fc7e79c0d1</td>\n      <td>acronym_identification</td>\n      <td>None</td>\n      <td>list_abbreviations</td>\n      <td>Given the tokens, list the abbreviations. Metr...</td>\n      <td>True</td>\n      <td>False</td>\n      <td>[Other]</td>\n      <td>None</td>\n      <td>List all the acryonyms in the following space-...</td>\n    </tr>\n    <tr>\n      <th>2084</th>\n      <td>8832e5f7-7c45-46da-b85f-71fcb444f264</td>\n      <td>acronym_identification</td>\n      <td>None</td>\n      <td>list_expansions</td>\n      <td>Given the tokens, list the expansion tokens. M...</td>\n      <td>True</td>\n      <td>False</td>\n      <td>[Other]</td>\n      <td>None</td>\n      <td>List all the expansions (meanings) of the acro...</td>\n    </tr>\n  </tbody>\n</table>\n<p>2085 rows Ã— 10 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_templates_data_frame()\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T09:46:46.133150Z",
     "start_time": "2024-01-22T09:46:39.494133Z"
    }
   },
   "id": "f296670b0cde6d79",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "templates = TemplateCollection()\n",
    "\n",
    "datasets = list(templates.datasets_templates.keys())\n",
    "\n",
    "prompts = {}\n",
    "for dataset, subset in datasets:\n",
    "    prompts_for_dataset = df.loc[(df[\"dataset\"] == dataset) & (df[\"subset\"] == subset)][\"jinja\"].to_list()\n",
    "    if len(prompts_for_dataset) == 0:\n",
    "        prompts_for_dataset = df.loc[(df[\"dataset\"] == dataset) & (df[\"subset\"].isnull())][\"jinja\"].to_list()\n",
    "    \n",
    "    prompts[f\"{dataset}_{subset}\"] = prompts_for_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T09:46:52.422371Z",
     "start_time": "2024-01-22T09:46:49.202793Z"
    }
   },
   "id": "4338373ab7dd4d18",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['wiki_qa_None',\n 'scitail_snli_format',\n 'scitail_tsv_format',\n 'crows_pairs_None']"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_sum = {f\"{dataset}_{subset}\": len(prompts[f\"{dataset}_{subset}\"]) for dataset, subset in datasets}\n",
    "list(prompt_sum.keys())[62:66]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T09:46:53.122842Z",
     "start_time": "2024-01-22T09:46:53.095027Z"
    }
   },
   "id": "965be9073d6585e6",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "20"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(prompt_sum.values())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T10:17:12.098109Z",
     "start_time": "2024-01-15T10:17:12.087541Z"
    }
   },
   "id": "20eef130c20d37ac",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of datasets 180\n"
     ]
    }
   ],
   "source": [
    "num_of_datasets = len(set(df['dataset'].to_list()))\n",
    "print(f\"number of datasets {num_of_datasets}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T10:17:12.886326Z",
     "start_time": "2024-01-15T10:17:12.876161Z"
    }
   },
   "id": "17eb30d315b5cf20",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of prompts: 2085\n"
     ]
    }
   ],
   "source": [
    "num_of_prompts = sum(prompt_sum.values())\n",
    "print(f\"number of prompts: {num_of_prompts}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T09:58:46.347814Z",
     "start_time": "2024-01-22T09:58:46.303673Z"
    }
   },
   "id": "ec423ade73ef7d18",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average prompt per dataset: 11.583333333333334\n"
     ]
    }
   ],
   "source": [
    "print(f\"average prompt per dataset: {num_of_prompts / num_of_datasets}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T10:17:15.745622Z",
     "start_time": "2024-01-15T10:17:15.736269Z"
    }
   },
   "id": "8460e85610093082",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "valid = {}\n",
    "invalid = {}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T10:42:50.531419Z",
     "start_time": "2024-01-15T10:42:50.476509Z"
    }
   },
   "id": "64303fbe08d6d1b8",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for key in prompt_sum.keys():\n",
    "    formatted_list = \"\\n\\n=============\\n\".join(f\"prompt_{index+1}: {value}\" for index, value in enumerate(prompts[key]))\n",
    "    prompt_str = f\"\"\"The prompts are delimited by triple backticks.\n",
    "\n",
    "```\n",
    "{formatted_list}\n",
    "```\n",
    "\"\"\"\n",
    "    \n",
    "    res = json.loads(get_completion(prompt_str, model=\"gpt-4\"))\n",
    "    tasks_sum = sum([r[\"numberOfPrompts\"] for r in res[\"result\"]])\n",
    "    \n",
    "    if prompt_sum[key] == tasks_sum:\n",
    "        valid[key] = {\n",
    "            \"task_sum\": tasks_sum,\n",
    "            \"response\": res\n",
    "        }\n",
    "    else:\n",
    "        invalid[key] = {\n",
    "            \"num_prompts\": prompt_sum[key],\n",
    "            \"task_sum\": tasks_sum,\n",
    "            \"response\": res\n",
    "        }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T11:00:24.339873Z",
     "start_time": "2024-01-15T10:42:59.539405Z"
    }
   },
   "id": "c8a432615a023d19",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: \n",
      "273\n",
      "Not Valid: \n",
      "6\n"
     ]
    }
   ],
   "source": [
    "print(f\"Valid: \\n{len(valid)}\")\n",
    "print(f\"Invalid: \\n{len(invalid)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T11:04:40.943649Z",
     "start_time": "2024-01-15T11:04:40.936575Z"
    }
   },
   "id": "5e89c5ff0816c372",
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "valid_json = json.dumps(valid, indent=4)\n",
    "with open(\"p3_classified_prompts.json\", \"w\") as f:\n",
    "    f.write(valid_json)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T11:09:45.136082Z",
     "start_time": "2024-01-15T11:09:45.096172Z"
    }
   },
   "id": "9f9dbaa799abeb1d",
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "invalid_json = json.dumps(invalid, indent=4)\n",
    "with open(\"p3_not_classified_prompts.json\", \"w\") as f:\n",
    "    f.write(invalid_json)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T11:09:46.376692Z",
     "start_time": "2024-01-15T11:09:46.371104Z"
    }
   },
   "id": "cc0ad941bb8a4c64",
   "execution_count": 38
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Manually classify invalid results..."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f39b21e6370f439e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_num_of_prompts_for_task(nlp_tasks_per_dataset) -> dict:\n",
    "    nlp_tasks = {}\n",
    "    for ds in prompt_sum.keys():\n",
    "        try:\n",
    "            for task in nlp_tasks_per_dataset[ds][\"response\"][\"result\"]:\n",
    "                nlp_tasks[task[\"nlptask\"]] = nlp_tasks.get(task[\"nlptask\"], 0) + task[\"numberOfPrompts\"]\n",
    "        except KeyError:\n",
    "            pass\n",
    "    return nlp_tasks"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T09:51:45.584149Z",
     "start_time": "2024-01-22T09:51:45.541715Z"
    }
   },
   "id": "f9dc1caee9917f04",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object <genexpr> at 0x7f8b61030c10>\n"
     ]
    }
   ],
   "source": [
    "gpt_classified = json.load(open(\"p3_classified_prompts.json\"))\n",
    "manually_classified = json.load(open(\"p3_manually_classified_prompts.json\"))\n",
    "\n",
    "tasks_per_dataset = get_num_of_prompts_for_task({**gpt_classified, **manually_classified})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T09:52:48.481094Z",
     "start_time": "2024-01-22T09:52:48.461782Z"
    }
   },
   "id": "4d9645c78424e086",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'Question Answering': 395,\n 'Text Generation': 263,\n 'Text Classification': 215,\n 'Natural Language Inference': 185,\n 'Sentiment Analysis': 145,\n 'Multiple Choice Question Answering': 121,\n 'Paraphrase Identification': 56,\n 'Named Entity Recognition': 45,\n 'Text Summarization': 44,\n 'Question Generation': 38,\n 'Text Completion': 38,\n 'Coreference Resolution': 28,\n 'Extractive Question Answering': 27,\n 'Pronoun Disambiguation': 26,\n 'Textual Entailment': 25,\n 'Commonsense Question Answering': 22,\n 'Summarization': 20,\n 'Cloze Test': 18,\n 'Cloze Task': 18,\n 'Emotion Detection': 16,\n 'Semantic Textual Similarity': 14,\n 'Text Simplification': 13,\n 'Duplicate Question Detection': 12,\n 'Intent Classification': 12,\n 'Natural Language Generation': 11,\n 'Word Sense Disambiguation': 10,\n 'Dialogue Systems': 10,\n 'Semantic Similarity': 10,\n 'Next Word Prediction': 10,\n 'Subjectivity Analysis': 10,\n 'Masked Language Modeling': 9,\n 'Topic Classification': 9,\n 'Entity Recognition': 8,\n 'Information Retrieval': 8,\n 'Answer Similarity': 8,\n 'Stereotype Detection': 8,\n 'Answer Verification': 8,\n 'Sentence Fusion': 8,\n 'Paraphrase Detection': 7,\n 'Title Generation': 7,\n 'Grammar Correction': 7,\n 'Sentence Simplification': 7,\n 'Dialogue Summarization': 6,\n 'Dialogue Generation': 6,\n 'Sentence Generation': 6,\n 'Sentence Compression': 6,\n 'Readability Assessment': 6,\n 'Information Extraction': 6,\n 'Query Understanding': 6,\n 'Knowledge Base to Natural Language Generation': 5,\n 'Grammatical Error Detection': 5,\n 'Table-to-Text': 5,\n 'Discourse Marker Prediction': 5,\n 'Fact Checking': 5,\n 'Semantic Relation Classification': 5,\n 'Text Evaluation': 5,\n 'Data-to-Text': 4,\n 'Text Correction': 4,\n 'Intent Detection': 4,\n 'Sentence Splitting': 4,\n 'Sentence Completion': 4,\n 'Code Generation': 3,\n 'Topic Modeling': 3,\n 'Relation Extraction': 3,\n 'Concept Extraction': 2,\n 'Negation Generation': 2,\n 'Temporal Question Classification': 2,\n 'Discourse Phenomena Identification': 2,\n 'Discourse Phenomenon Identification': 2,\n 'Keyword Extraction': 2,\n 'Code Explanation': 2,\n 'Natural Language to Knowledge Base Generation': 1,\n 'Dialogue Order Detection': 1,\n 'Dialogue Understanding': 1,\n 'Dialogue Response Generation': 1,\n 'Code Review': 1,\n 'Code Correction': 1,\n 'Topic Generation': 1,\n 'Headline Generation': 1,\n 'Question Classification': 1,\n 'Paraphrase Generation': 1,\n 'Contextual Understanding': 1,\n 'Text Elaboration': 1,\n 'Answerability Classification': 1,\n 'Text Transformation': 1}"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(sorted(tasks_per_dataset.items(), key=lambda item: item[1], reverse=True))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T09:53:48.210786Z",
     "start_time": "2024-01-22T09:53:48.149199Z"
    }
   },
   "id": "b3c9f9b97085630e",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "85"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tasks_per_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T10:27:22.136308Z",
     "start_time": "2024-01-22T10:27:22.106722Z"
    }
   },
   "id": "3170c90de2768702",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "babce3bd358a3cda"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
